{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Chapter8.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMweW7nY9vJqPb6nkp1XFDD"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_feZb3i1I5qz"},"source":["# 8章：ニューラルネット\n","第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ。  "]},{"cell_type":"markdown","metadata":{"id":"zbLnQEMeK-eC"},"source":["## 70. 単語ベクトルの和による特徴量\n","\n","問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例$x_i$の特徴ベクトル$\\boldsymbol{x}_i$を並べた行列$X$と正解ラベルを並べた行列（ベクトル）$Y$を作成したい．\n","\n","$$\n","X = \\begin{pmatrix} \n","  \\boldsymbol{x}_1 \\\\ \n","  \\boldsymbol{x}_2 \\\\ \n","  \\dots \\\\ \n","  \\boldsymbol{x}_n \\\\ \n","\\end{pmatrix} \\in \\mathbb{R}^{n \\times d},\n","Y = \\begin{pmatrix} \n","  y_1 \\\\ \n","  y_2 \\\\ \n","  \\dots \\\\ \n","  y_n \\\\ \n","\\end{pmatrix} \\in \\mathbb{N}^{n}\n","$$\n","\n","\n"," ここで，$n$は学習データの事例数であり，$\\boldsymbol x_i \\in \\mathbb{R}^d$と$y_i \\in \\mathbb N$はそれぞれ，$i \\in \\{1, \\dots, n\\}$番目の事例の特徴量ベクトルと正解ラベルを表す．\n"," なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．$\\mathbb N_{<4}$で$4$未満の自然数（$0$を含む）を表すことにすれば，任意の事例の正解ラベル$y_i$は$y_i \\in \\mathbb N_{<4}$で表現できる．\n"," 以降では，ラベルの種類数を$L$で表す（今回の分類タスクでは$L=4$である）．\n","\n"," $i$番目の事例の特徴ベクトル$\\boldsymbol x_i$は，次式で求める．\n","\n"," $$\\boldsymbol x_i = \\frac{1}{T_i} \\sum_{t=1}^{T_i} \\mathrm{emb}(w_{i,t})$$\n","\n"," ここで，$i$番目の事例は$T_i$個の（記事見出しの）単語列$(w_{i,1}, w_{i,2}, \\dots, w_{i,T_i})$から構成され，$\\mathrm{emb}(w) \\in \\mathbb{R}^d$は単語$w$に対応する単語ベクトル（次元数は$d$）である．  \n"," すなわち，$i$番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものが$\\boldsymbol x_i$である．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．$300$次元の単語ベクトルを用いたので，$d=300$である．  \n"," $i$番目の事例のラベル$y_i$は，次のように定義する．\n","\n","$$\n","y_i = \\begin{cases}\n","0 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「ビジネス」カテゴリの場合}) \\\\\n","1 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「科学技術」カテゴリの場合}) \\\\\n","2 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「エンターテイメント」カテゴリの場合}) \\\\\n","3 & (\\mbox{記事}\\boldsymbol x_i\\mbox{が「健康」カテゴリの場合}) \\\\\n","\\end{cases}\n","$$\n","\n","なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n","\n","以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n","\n"," + 学習データの特徴量行列: $X_{\\rm train} \\in \\mathbb{R}^{N_t \\times d}$\n"," + 学習データのラベルベクトル: $Y_{\\rm train} \\in \\mathbb{N}^{N_t}$\n"," + 検証データの特徴量行列: $X_{\\rm valid} \\in \\mathbb{R}^{N_v \\times d}$\n"," + 検証データのラベルベクトル: $Y_{\\rm valid} \\in \\mathbb{N}^{N_v}$\n"," + 評価データの特徴量行列: $X_{\\rm test} \\in \\mathbb{R}^{N_e \\times d}$\n"," + 評価データのラベルベクトル: $Y_{\\rm test} \\in \\mathbb{N}^{N_e}$\n","\n","なお，$N_t, N_v, N_e$はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"]},{"cell_type":"markdown","metadata":{"id":"2GCShFBPtZB0"},"source":["## 71. 単層ニューラルネットワークによる予測\n","問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n","\n","$$ \n","\\hat{y}_1=softmax(x_1W),\\\\\\hat{Y}=softmax(X_{[1:4]}W)\n","$$\n","\n","\n","ただし，$softmax$はソフトマックス関数，$X_{[1:4]}∈\\mathbb{R}^{4×d}$は特徴ベクトル$x_1$,$x_2$,$x_3$,$x_4$を縦に並べた行列である．\n","\n","$$\n","X_{[1:4]}=\\begin{pmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\end{pmatrix}\n","$$\n","\n","行列$W \\in \\mathbb{R}^{d \\times L}$は単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．  \n","なお，$\\hat{\\boldsymbol y_1} \\in \\mathbb{R}^L$は未学習の行列$W$で事例$x_1$を分類したときに，各カテゴリに属する確率を表すベクトルである．\n","同様に，$\\hat{Y} \\in \\mathbb{R}^{n \\times L}$は，学習データの事例$x_1, x_2, x_3, x_4$について，各カテゴリに属する確率を行列として表現している．\n"]},{"cell_type":"markdown","metadata":{"id":"S2AZ3dWHJqo9"},"source":["## 72. 損失と勾配の計算\n","\n","学習データの事例x1\n","と事例集合x1,x2,x3,x4\n","に対して，クロスエントロピー損失と，行列W\n","に対する勾配を計算せよ．なお，ある事例xi\n","に対して損失は次式で計算される．\n","\n","$$\n","l_i=−log[事例x_iがy_iに分類される確率]\n","$$\n","\n","ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"]},{"cell_type":"markdown","metadata":{"id":"uudzTu5mWLp1"},"source":["## 73. 確率的勾配降下法による学習\n","\n","確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列W\n","を学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"]},{"cell_type":"markdown","metadata":{"id":"x6uSmaljF8H0"},"source":["## 74. 正解率の計測\n","\n","問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"]},{"cell_type":"markdown","metadata":{"id":"OKnCbpspuexA"},"source":["## 75. 損失と正解率のプロット\n","問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"]},{"cell_type":"markdown","metadata":{"id":"PnR6u561QW8I"},"source":["## 76. チェックポイント\n","\n","問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rpR29zZErLhv"},"source":["## 77. ミニバッチ化\n","\n","問題76のコードを改変し，B\n","事例ごとに損失・勾配を計算し，行列W\n","の値を更新せよ（ミニバッチ化）．B\n","の値を1,2,4,8,…\n","と変化させながら，1エポックの学習に要する時間を比較せよ．\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hv4gAVHc9Zkj"},"source":["## 78. GPU上での学習\n","\n","問題77のコードを改変し，GPU上で学習を実行せよ．"]},{"cell_type":"markdown","metadata":{"id":"4pf9znncKUyM"},"source":["## 79. 多層ニューラルネットワーク\n","\n","問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ"]}]}